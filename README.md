# Enlitens AI - Scientific Knowledge Base & Document Processing System

**A neurodiversity-affirming, trauma-informed AI system for processing scientific literature and building comprehensive knowledge bases.**

---

## ğŸ¯ What is Enlitens?

Enlitens is a production-grade document processing pipeline that:
- Extracts scientific content from PDFs using Docling + Llama 3.1 8B
- Validates and enriches extractions with Gemini 2.5 Pro (1M context)
- Stores knowledge in PostgreSQL, ChromaDB, and Neo4j
- Provides a real-time dashboard for monitoring
- Runs entirely on your own infrastructure (GPU + cloud APIs)

---

## ğŸ“ Project Structure

```
enlitens-ai/
â”œâ”€â”€ src/                              # Core processing pipeline
â”‚   â”œâ”€â”€ pipeline/                     # Document pipeline orchestration
â”‚   â”œâ”€â”€ integrations/                 # External APIs (Gemini CLI, Wikipedia, etc.)
â”‚   â”œâ”€â”€ retrieval/                    # Vector store & external search
â”‚   â”œâ”€â”€ persistence/                  # PostgreSQL & Neo4j publishers
â”‚   â””â”€â”€ utils/                        # Logging, terminology, helpers
â”‚
â”œâ”€â”€ process_pdfs/                     # PDF extraction & enrichment
â”‚   â”œâ”€â”€ extraction.py                 # Scientific content extraction (Llama)
â”‚   â”œâ”€â”€ enrichment.py                 # External enrichment (Wikipedia, Crossref, etc.)
â”‚   â””â”€â”€ docling_wrapper.py            # PDF parsing (Docling)
â”‚
â”œâ”€â”€ dashboard/                        # Real-time monitoring dashboard
â”‚   â”œâ”€â”€ server.py                     # Flask API
â”‚   â”œâ”€â”€ templates/                    # HTML templates
â”‚   â””â”€â”€ static/                       # CSS/JS
â”‚
â”œâ”€â”€ scripts/                          # Organized scripts
â”‚   â”œâ”€â”€ ingestion/                    # Document processing scripts
â”‚   â”œâ”€â”€ dashboard/                    # Dashboard management
â”‚   â”œâ”€â”€ model_management/             # vLLM startup scripts
â”‚   â”œâ”€â”€ backup/                       # Backup scripts
â”‚   â””â”€â”€ utilities/                    # Testing & utilities
â”‚
â”œâ”€â”€ ops/                              # Operations & deployment
â”‚   â”œâ”€â”€ systemd/                      # Systemd service units
â”‚   â””â”€â”€ cloudflare/                   # Cloudflare Tunnel config
â”‚
â”œâ”€â”€ docs/                             # Documentation
â”‚   â””â”€â”€ hosting_guide.md              # Full deployment guide
â”‚
â”œâ”€â”€ config/                           # Configuration
â”‚   â””â”€â”€ local_models.yaml             # Model definitions
â”‚
â”œâ”€â”€ enlitens_corpus/                  # Document corpus
â”‚   â”œâ”€â”€ input_pdfs/                   # PDFs to process
â”‚   â”œâ”€â”€ processed/                    # Completed PDFs (organized by date)
â”‚   â””â”€â”€ failed/                       # Failed PDFs
â”‚
â”œâ”€â”€ enlitens_knowledge_base/          # Knowledge base storage
â”‚   â””â”€â”€ ledger/                       # JSONL ledger (one entry per document)
â”‚
â”œâ”€â”€ data/                             # Database storage
â”‚   â”œâ”€â”€ vector_store/chroma/          # ChromaDB vector store
â”‚   â””â”€â”€ neo4j/                        # Neo4j graph database
â”‚
â”œâ”€â”€ models/                           # LLM model files (Llama 3.1 8B)
â”œâ”€â”€ cache/                            # Docling cache
â”œâ”€â”€ logs/                             # Processing logs
â”œâ”€â”€ backups/                          # Automated backups
â””â”€â”€ requirements.txt                  # Python dependencies
```

---

## ğŸš€ Quick Start

### 1. Prerequisites
- **GPU**: NVIDIA GPU with 24GB+ VRAM (for Llama 3.1 8B via vLLM)
- **RAM**: 32GB+ recommended
- **Disk**: 100GB+ free space
- **OS**: Ubuntu 20.04+ or similar Linux distribution

### 2. Installation
```bash
# Clone the repository
cd /home/antons-gs/enlitens-ai

# Activate virtual environment
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt
```

### 3. Start Processing Documents
```bash
# Start the dashboard (monitor at https://dashboard.enlitens.com)
bash scripts/dashboard/start_dashboard.sh

# Start document ingestion (processes all PDFs in enlitens_corpus/input_pdfs/)
cd /home/antons-gs/enlitens-ai
ENLITENS_ENABLE_POSTGRES=1 \
ENLITENS_ENABLE_NEO4J=1 \
ENLITENS_ENABLE_VECTOR_MIRROR=1 \
DATABASE_URL=postgresql:///enlitens \
ENLITENS_NEO4J_URI=bolt://localhost:7687 \
ENLITENS_NEO4J_USER=neo4j \
ENLITENS_NEO4J_PASSWORD=YourPassword \
./venv/bin/python scripts/ingestion/run_ingest_batch.py --auto-start --auto-stop
```

---

## ğŸ“Š System Architecture

### Processing Pipeline
1. **Docling** (CPU) - Extracts text, tables, and metadata from PDFs
2. **Llama 3.1 8B** (GPU) - Extracts scientific content (background, methods, findings, etc.)
3. **External Enrichment** - Fetches Wikipedia, Crossref, Semantic Scholar data
4. **Gemini 2.5 Pro** (Cloud API) - Validates and consolidates all outputs
5. **Storage** - Writes to PostgreSQL, ChromaDB, and Neo4j

### Tech Stack
- **PDF Parsing**: Docling (CPU-based OCR + layout detection)
- **LLM Inference**: vLLM (GPU-accelerated Llama 3.1 8B)
- **Validation**: Gemini CLI (Gemini 2.5 Pro with 1M context)
- **Databases**: PostgreSQL 16 (with pgvector), Neo4j 5.x, ChromaDB
- **Dashboard**: Flask + Jinja2 + responsive CSS
- **Deployment**: Systemd + Cloudflare Tunnel

---

## ğŸ›ï¸ Configuration

### Environment Variables
All secrets are stored in `/etc/enlitens/enlitens.env`:
```bash
ENLITENS_ENABLE_POSTGRES=1
ENLITENS_ENABLE_NEO4J=1
ENLITENS_ENABLE_VECTOR_MIRROR=1
DATABASE_URL=postgresql:///enlitens
ENLITENS_NEO4J_URI=bolt://localhost:7687
ENLITENS_NEO4J_USER=neo4j
ENLITENS_NEO4J_PASSWORD=YourPassword
```

### Model Configuration
Edit `config/local_models.yaml` to configure LLM models.

---

## ğŸ“ˆ Monitoring

### Dashboard
Access the real-time dashboard at:
- **Local**: http://localhost:5000
- **Remote**: https://dashboard.enlitens.com (via Cloudflare Tunnel)

The dashboard shows:
- Documents processed, pending, and failed
- GPU usage and model status
- Recent processing activity
- Error logs

### Logs
```bash
# View processing logs
tail -f logs/processing.log

# View dashboard logs
tail -f logs/dashboard.log
```

---

## ğŸ”§ Maintenance

### Backups
```bash
# Manual backup
bash scripts/backup/run_backup.sh

# Automated backups are stored in backups/ directory
```

### Clear Cache
```bash
# Clear Docling cache
rm -rf cache/*

# Clear logs
rm -rf logs/*
```

### Restart Services
```bash
# Restart dashboard
bash scripts/dashboard/start_dashboard.sh

# Restart vLLM
bash scripts/model_management/start_local_model.sh llama
```

---

## ğŸ“– Documentation

- **[Hosting Guide](docs/hosting_guide.md)** - Full deployment instructions
- **[Architecture](docs/ARCHITECTURE_V2_SUMMARY.md)** - System architecture overview
- **[Knowledge Base](docs/README_KNOWLEDGE_BASE.md)** - Knowledge base structure

---

## ğŸ› ï¸ Development

### Adding New PDFs
```bash
# Add PDFs to the input directory
cp your_paper.pdf enlitens_corpus/input_pdfs/

# Run ingestion
python scripts/ingestion/run_ingest_batch.py --auto-start --auto-stop
```

### Testing
```bash
# Run a single document pilot
python scripts/utilities/run_single_document_pilot.py
```

---

## ğŸ“ License

This project is proprietary and confidential.

---

## ğŸ¤ Support

For questions or issues, contact the development team.
