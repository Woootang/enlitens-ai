# Extracted Text for What_is_the_evidence_for_neural_synchrony_or_br.pdf

Yes, there is robust evidence for neural synchrony (brain-to-brain coupling)
between a storyteller and listener during narrative communication.

1. Introduction

Neural synchrony, or brain-to-brain coupling, refers to the phenomenon where the neural activity of a speaker and

a listener becomes temporally aligned during communication, particularly storytelling. A substantial body of

research using fMRI, EEG, and fNIRS demonstrates that when a person tells a story and another listens, their brain

activity patterns become synchronized, especially in regions associated with language, attention, and emotion

processing (Stephens et al., 2010; Liu et al., 2016; Pérez et al., 2017; Silbert et al., 2014; Chang et al., 2024; Chang et

al., 2023; Kuhlen et al., 2012; Liu et al., 2020; Xie et al., 2021; Smirnov et al., 2019; Nummenmaa et al., 2014; Dikker

et al., 2014; Hong et al., 2025). This synchrony is not merely a byproduct of shared sensory input but is closely

linked to successful communication, comprehension, and engagement. The strength of neural coupling predicts

how well listeners understand and remember stories, and is modulated by factors such as emotional content,

narrative engagement, and even the linguistic features of the story (Smirnov et al., 2019; Stephens et al., 2010;

Silbert et al., 2014; Nummenmaa et al., 2014; Xie et al., 2021; Hong et al., 2025; Dikker et al., 2014). Importantly, this

coupling diminishes or disappears when communication fails or when the story is presented in an

incomprehensible language (Liu et al., 2016; Green et al., 2024; Green et al., 2020; Liu et al., 2020). These findings

suggest that neural synchrony is a fundamental mechanism underlying effective narrative communication.

2. Methods

A comprehensive search was conducted across over 170 million research papers in Consensus, including sources

such as Semantic Scholar and PubMed. The search strategy targeted studies on neural synchrony, brain-to-brain
coupling, and inter-brain synchronization during storytelling and narrative communication, using diverse

neuroimaging modalities (fMRI, EEG, fNIRS). In total, 1,027 papers were identified, 700 were screened, 474 were

deemed eligible, and the top 50 most relevant papers were included in this review.

Search Strategy

Identification

N = 1027

→

Screening

N = 700

→

Eligibility

N = 474

→

Included

N = 50

Identified 1021 papers

Removed papers with

Removed papers with low

Selected the top 50

that matched 20
Consensus searches

1021 identified

missing abstracts

semantic relevance to
each search

highest quality papers
after final ranking

226 removed

424 removed

Identified 6 papers from

citation graph exploration

6 identified

Removed duplicates

327 removed

FIGURE 1  Flow diagram of the literature search and selection process.

1 / 9

Eight unique search strategies were used, focusing on foundational concepts, storytelling-specific evidence,

methodological diversity, and critiques of neural synchrony research.

3. Results

3.1 Evidence for Neural Synchrony in Storytelling

Multiple studies using fMRI, EEG, and fNIRS have demonstrated significant neural coupling between speakers and

listeners during storytelling. This synchrony is observed in language, auditory, and higher-order brain regions, and is

temporally aligned with the narrative flow (Stephens et al., 2010; Liu et al., 2016; Pérez et al., 2017; Silbert et al.,

2014; Chang et al., 2024; Chang et al., 2023; Kuhlen et al., 2012; Liu et al., 2020; Xie et al., 2021; Smirnov et al.,

2019; Nummenmaa et al., 2014; Dikker et al., 2014; Hong et al., 2025). The coupling is often time-lagged, with the

listener's brain activity following the speaker's, reflecting information transfer and comprehension (Stephens et al.,

2010; Liu et al., 2016; Chang et al., 2024; Chang et al., 2023; Silbert et al., 2014; Kuhlen et al., 2012).

3.2 Modulators of Neural Synchrony

Neural synchrony is enhanced by emotional content, narrative engagement, and predictability. Emotional stories

increase synchrony in regions involved in emotion and attention, while higher engagement and predictability

strengthen coupling in language and default mode networks (Smirnov et al., 2019; Nummenmaa et al., 2014; Ohad

& Yeshurun, 2023; Song et al., 2020; Xie et al., 2021; Dikker et al., 2014; Hong et al., 2025). Conversely, effortful or
non-native speech, or lack of comprehension, reduces synchrony (Green et al., 2024; Green et al., 2020; Li et al.,

2022; Li et al., 2021).

3.3 Behavioral and Cognitive Correlates

The degree of neural coupling predicts listeners' comprehension, recall, and even interpersonal closeness. Stronger

synchrony is associated with better understanding, memory, and social connection between speaker and listener

(Stephens et al., 2010; Silbert et al., 2014; Xie et al., 2021; Piazza et al., 2020; Smirnov et al., 2019; Chang et al.,
2024; Chang et al., 2023; Kuhlen et al., 2012; Liu et al., 2020; Dikker et al., 2014). Synchrony also reflects shared

attention and engagement, as measured by physiological and behavioral markers (Kang & Wheatley, 2017;

Wohltjen et al., 2023; Lambrechts et al., 2025; Madsen & Parra, 2024; Hammond et al., 2024; Hammond et al.,
2023; Carter et al., 2025).

3.4 Methodological Diversity and Limitations

Studies employ a range of neuroimaging techniques (fMRI, EEG, fNIRS), each with strengths and limitations. While

most evidence supports the existence of neural synchrony, some studies highlight methodological challenges, such

as disentangling true inter-brain coupling from shared stimulus effects or individual differences in interpretation
(Chang et al., 2024; Chang et al., 2023; Kuhlen et al., 2012; Finn et al., 2018; Lyu et al., 2023; Beauvoir, 2015; Chang

et al., 2021; Chen et al., 2025).

2 / 9

Key Papers

Paper

Modality

Sample

Main Findings

(Stephens et
al., 2010)

fMRI

Speaker +
Listeners

Speaker-listener neural coupling predicts comprehension;
coupling vanishes when communication fails

(Liu et al.,
2016)

fNIRS,
fMRI

3 speakers, 15
listeners

Brain-to-brain coupling during storytelling; coupling absent
when communication fails

(Pérez et al.,
2017)

(Silbert et al.,
2014)

(Smirnov et al.,
2019)

EEG

Dyads

Brain oscillations synchronized between speaker and
listener during oral narratives

fMRI

fMRI

Speaker +
Listeners

Widespread bilateral coupling in linguistic and nonlinguistic
areas during narrative production and comprehension

2 speakers, 16
listeners

Emotional alignment increases neural synchrony in emotion
and attention regions

FIGURE 2  Comparison of key studies on neural synchrony between storyteller and listener.

Top Contributors

Type

Name

Papers

Author

U. Hasson

(Stephens et al., 2010; Liu et al., 2016; Chang et al., 2024; Chang et al.,

2023; Silbert et al., 2014; Nguyen et al., 2019; Suzuki et al., 2018; Chang et
al., 2021; Dikker et al., 2014; Baldassano et al., 2018)

Author

Lauren J. Silbert

(Stephens et al., 2010; Silbert et al., 2014; Dikker et al., 2014)

Author

Claire H C Chang

(Chang et al., 2024; Chang et al., 2023; Chang et al., 2021)

Journal

Proceedings of the
National Academy of

(Stephens et al., 2010; Silbert et al., 2014; Song et al., 2020; Chang et al.,
2021)

Sciences

Journal

NeuroImage

(Ohad & Yeshurun, 2023; Nummenmaa et al., 2014; Nguyen et al., 2019;

Ross et al., 2022)

Journal

Scientific Reports

(Liu et al., 2016; Pérez et al., 2017; Hammond et al., 2024; Wohltjen et al.,

2023)

FIGURE 3  Authors & journals that appeared most frequently in the included papers.

3 / 9

4. Discussion

The evidence for neural synchrony between storyteller and listener is robust, spanning multiple neuroimaging

modalities and experimental paradigms (Stephens et al., 2010; Liu et al., 2016; Pérez et al., 2017; Silbert et al., 2014;

Chang et al., 2024; Chang et al., 2023; Kuhlen et al., 2012; Liu et al., 2020; Xie et al., 2021; Smirnov et al., 2019;

Nummenmaa et al., 2014; Dikker et al., 2014; Hong et al., 2025). This synchrony is not simply a reflection of shared

sensory input but is closely tied to successful communication, comprehension, and engagement. The temporal

dynamics of coupling—often with the listener lagging the speaker—mirror the flow of information and
understanding (Stephens et al., 2010; Liu et al., 2016; Chang et al., 2024; Chang et al., 2023; Silbert et al., 2014;

Kuhlen et al., 2012). Emotional content, engagement, and predictability further modulate the strength and spatial

extent of synchrony (Smirnov et al., 2019; Nummenmaa et al., 2014; Ohad & Yeshurun, 2023; Song et al., 2020; Xie

et al., 2021; Dikker et al., 2014; Hong et al., 2025).

However, methodological challenges remain. Disentangling true inter-brain coupling from common stimulus-driven

effects is complex, and individual differences in interpretation, language proficiency, and cognitive effort can

influence synchrony (Chang et al., 2024; Chang et al., 2023; Kuhlen et al., 2012; Finn et al., 2018; Lyu et al., 2023;

Beauvoir, 2015; Chang et al., 2021; Chen et al., 2025). Some studies report reduced or absent coupling when

comprehension fails or when communication is effortful, highlighting the functional significance of neural
synchrony (Liu et al., 2016; Green et al., 2024; Green et al., 2020; Li et al., 2022; Li et al., 2021).

Overall, neural synchrony appears to be a fundamental mechanism for effective narrative communication,

supporting shared understanding, memory, and social connection.

4 / 9

Claims and Evidence Table

Evidence

Strength

Strong

Claim

Neural synchrony

occurs between
storyteller and listener

during narrative
communication

Strength of neural
coupling predicts

comprehension and
recall

Emotional and
engaging stories

enhance neural
synchrony

Strong

Strong

Reasoning

Papers

Multiple convergent

(Stephens et al., 2010; Liu et al.,

studies using fMRI, EEG,
and fNIRS show robust,

reproducible coupling

Stronger coupling is
associated with better

understanding and
memory

2016; Pérez et al., 2017; Silbert et al.,
2014; Chang et al., 2024; Chang et

al., 2023; Kuhlen et al., 2012; Liu et
al., 2020; Smirnov et al., 2019;

Nummenmaa et al., 2014; Dikker et
al., 2014; Hong et al., 2025)

(Stephens et al., 2010; Silbert et al.,
2014; Xie et al., 2021; Piazza et al.,

2020; Smirnov et al., 2019; Chang et
al., 2024; Chang et al., 2023; Kuhlen

et al., 2012; Liu et al., 2020; Dikker
et al., 2014)

Emotional arousal and
engagement increase

synchrony in relevant
brain regions

(Smirnov et al., 2019; Nummenmaa
et al., 2014; Ohad & Yeshurun, 2023;

Song et al., 2020; Xie et al., 2021;
Dikker et al., 2014; Hong et al., 2025)

Neural synchrony
diminishes when

communication fails or
is effortful

Moderate

Coupling is reduced or
absent with

(Liu et al., 2016; Green et al., 2024;
Green et al., 2020; Li et al., 2022; Li

incomprehensible
language or high

cognitive effort

et al., 2021)

Methodological

challenges exist in
isolating true inter-

brain coupling

Difficult to separate

(Chang et al., 2024; Chang et al.,

Moderate

stimulus-driven effects
from genuine brain-to-

brain coupling

2023; Kuhlen et al., 2012; Finn et al.,
2018; Lyu et al., 2023; Beauvoir,

2015; Chang et al., 2021; Chen et al.,
2025)

Individual differences
(e.g., language

proficiency,
personality) modulate

synchrony

Moderate

Synchrony varies with
listener traits,

interpretation, and
engagement

(Ohad & Yeshurun, 2023; Finn et al.,
2018; Lyu et al., 2023; Beauvoir,

2015; Xie et al., 2021; Dikker et al.,
2014)

FIGURE  Key claims and support evidence identified in these papers.

5 / 9

5. Conclusion

There is strong, multi-modal evidence that neural synchrony (brain-to-brain coupling) occurs between a storyteller
and listener during narrative communication, and that this synchrony is functionally significant for comprehension,

memory, and social connection. The phenomenon is robust across methods and contexts, but future research

should address methodological challenges and individual differences.

5.1 Research Gaps

While the evidence for neural synchrony is strong, gaps remain in understanding the causal mechanisms, the role of

individual differences, and the application of these findings in real-world, interactive settings. Most studies focus

on passive listening rather than live, reciprocal storytelling, and there is limited research on diverse populations and

naturalistic environments.

Research Gaps Matrix

Topic / Attribute

fMRI

EEG

fNIRS

Children

Non-native Language

Speaker-listener synchrony

Engagement modulation

Emotional content

Live/reciprocal interaction

Real-world/naturalistic settings

12

6

5

2

3

5

2

1

1

1

7

2

2

1

2

2

1

GAP

GAP

1

3

1

GAP

GAP

GAP

FIGURE  Matrix showing research coverage by topic and study attribute; gaps indicate areas for future research.

5.2 Open Research Questions

Future research should explore the causal mechanisms of neural synchrony, its role in live, interactive storytelling,
and its variability across individuals and contexts.

6 / 9

Question

Why

What are the causal mechanisms underlying neural
synchrony during live, reciprocal storytelling?

Understanding causality will clarify whether synchrony
drives comprehension or is a byproduct, and inform

interventions for communication disorders.

How do individual differences (e.g., personality,

Identifying these factors can help tailor educational and

language proficiency) affect neural synchrony and
communication outcomes?

therapeutic approaches to diverse populations.

Can neural synchrony be enhanced in real-world
settings to improve learning, memory, or social

Translating lab findings to practical applications could
benefit education, therapy, and media design.

connection?

FIGURE  Open research questions for future investigation into neural synchrony in storytelling.

In summary, neural synchrony between storyteller and listener is a well-supported phenomenon that underpins
effective narrative communication, but important questions remain about its mechanisms and applications.

These papers were sourced and synthesized using Consensus, an AI-powered search engine for research. Try it at

https://consensus.app

References

Smirnov, D., Saarimäki, H., Glerean, E., Hari, R., Sams, M., & Nummenmaa, L. (2019). Emotions amplify speaker–

listener neural alignment. Human Brain Mapping, 40, 4777 - 4788. https://doi.org/10.1002/hbm.24736

Liu, Y., Piazza, E., Simony, E., Shewokis, P., Onaral, B., Hasson, U., & Ayaz, H. (2016). Measuring speaker–listener
neural coupling with functional near infrared spectroscopy. Scientific Reports, 7.

https://doi.org/10.1038/srep43293

Chang, C., Nastase, S., Zadbood, A., & Hasson, U. (2024). How a speaker herds the audience: multibrain neural
convergence over time during naturalistic storytelling. Social Cognitive and Affective Neuroscience, 19.

https://doi.org/10.1093/scan/nsae059

Pérez, A., Carreiras, M., & Duñabeitia, J. (2017). Brain-to-brain entrainment: EEG interbrain synchronization while
speaking and listening. Scientific Reports, 7. https://doi.org/10.1038/s41598-017-04464-4

Green, G., Jacewicz, E., Santosa, H., Arzbecker, L., & Fox, R. (2024). Evaluating Speaker-Listener Cognitive Effort in

Speech Communication Through Brain-to-Brain Synchrony: A Pilot Functional Near-Infrared Spectroscopy
Investigation.. Journal of speech, language, and hearing research : JSLHR, 1-21.

https://doi.org/10.1044/2024_JSLHR-23-00476

Ohad, T., & Yeshurun, Y. (2023). Neural synchronization as a function of engagement with the narrative.
NeuroImage, 276. https://doi.org/10.1016/j.neuroimage.2023.120215

Stephens, G., Silbert, L., & Hasson, U. (2010). Speaker–listener neural coupling underlies successful

communication. Proceedings of the National Academy of Sciences, 107, 14425 - 14430.
https://doi.org/10.1073/pnas.1008662107

7 / 9

Song, H., Finn, E., & Rosenberg, M. (2020). Neural signatures of attentional engagement during narratives and its

consequences for event memory. Proceedings of the National Academy of Sciences, 118.
https://doi.org/10.1101/2020.08.26.266320

Liu, L., Zhang, Y., Zhou, Q., Garrett, D., Lu, C., Chen, A., Qiu, J., & Ding, G. (2020). Auditory-Articulatory Neural

Alignment between Listener and Speaker during Verbal Communication.. Cerebral cortex.
https://doi.org/10.1093/cercor/bhz138

Chang, C., Nastase, S., & Hasson, U. (2023). How a speaker herds the audience: Multi-brain neural convergence

over time during naturalistic storytelling. bioRxiv. https://doi.org/10.1101/2023.10.10.561803

Kang, O., & Wheatley, T. (2017). Pupil Dilation Patterns Spontaneously Synchronize Across Individuals During
Shared Attention. Journal of Experimental Psychology: General, 146, 569–576.

https://doi.org/10.1037/xge0000271

Hong, C., Teng, X., Li, Y., Hsu, S., Tsao, F., Wong, P., & Feng, G. (2025). Language-specific Tonal Features Drive
Speaker-Listener Neural Synchronization. **.

Madsen, J., & Parra, L. (2024). Bidirectional brain-body interactions during natural story listening.. Cell reports, 43

4, 114081. https://doi.org/10.1016/j.celrep.2024.114081

Silbert, L., Honey, C., Simony, E., Poeppel, D., & Hasson, U. (2014). Coupled neural systems underlie the production
and comprehension of naturalistic narrative speech. Proceedings of the National Academy of Sciences, 111, E4687 -

E4696. https://doi.org/10.1073/pnas.1323812111

Nummenmaa, L., Saarimäki, H., Glerean, E., Gotsopoulos, A., Jääskeläinen, I., Hari, R., & Sams, M. (2014). Emotional
speech synchronizes brains across listeners and engages large-scale dynamic brain networks. Neuroimage, 102,

498 - 509. https://doi.org/10.1016/j.neuroimage.2014.07.063

Nguyen, M., Vanderwal, T., & Hasson, U. (2019). Shared understanding of narratives is correlated with shared neural
responses. NeuroImage, 184, 161-170. https://doi.org/10.1016/j.neuroimage.2018.09.010

Green, G., Jacewicz, E., Arzbecker, L., Santosa, H., & Fox, R. (2020). Brain-to-brain synchrony in assessing listening

effort. Journal of the Acoustical Society of America, 148, 2507-2507. https://doi.org/10.1121/1.5146965

Xie, E., Yin, Q., Li, K., Nastase, S., Zhang, R., Wang, N., & Li, X. (2021). Sharing Happy Stories Increases
Interpersonal Closeness: Interpersonal Brain Synchronization as a Neural Indicator. eNeuro, 8.

https://doi.org/10.1523/ENEURO.0245-21.2021

Lyu, Y., Su, Z., Neumann, D., Meidenbauer, K., & Leong, Y. (2023). Hostile Attribution Bias Shapes Neural Synchrony
in the Left Ventromedial Prefrontal Cortex during Ambiguous Social Narratives. The Journal of Neuroscience, 44.

https://doi.org/10.1101/2023.07.11.548407

Beauvoir, S. (2015). The Function of Neural Synchrony Between Speakers and Listeners During Language
Comprehension. **.

Wohltjen, S., Tóth, B., Boncz, Á., & Wheatley, T. (2023). Synchrony to a beat predicts synchrony with other minds.

Scientific Reports, 13. https://doi.org/10.1038/s41598-023-29776-6

Lambrechts, L., Accou, B., Vanthornhout, J., Boets, B., & Francart, T. (2025). In sync with sound: Interpersonal
synchronization as an objective measure of listening engagement. bioRxiv.

https://doi.org/10.1101/2025.02.26.639799

Ross, L., Molholm, S., Butler, J., Del Bene, V., & Foxe, J. (2022). Neural correlates of multisensory enhancement in
audiovisual narrative speech perception: A fMRI investigation. NeuroImage, 263.

https://doi.org/10.1016/j.neuroimage.2022.119598

8 / 9

Kuhlen, A., Allefeld, C., & Haynes, J. (2012). Content-specific coordination of listeners' to speakers' EEG during

communication. Frontiers in Human Neuroscience, 6. https://doi.org/10.3389/fnhum.2012.00266

Dikker, S., Silbert, L., Hasson, U., & Zevin, J. (2014). On the Same Wavelength: Predictable Language Enhances
Speaker–Listener Brain-to-Brain Synchrony in Posterior Superior Temporal Gyrus. The Journal of Neuroscience, 34,

6267 - 6272. https://doi.org/10.1523/JNEUROSCI.3796-13.2014

Hammond, H., Armstrong, M., Thomas, G., Dalmaijer, E., Bull, D., & Gilchrist, I. (2024). Narrative predicts cardiac
synchrony in audiences. Scientific Reports, 14. https://doi.org/10.1038/s41598-024-73066-8

Hammond, H., Armstrong, M., Thomas, G., Dalmaijer, E., & Gilchrist, I. (2023). Narrative, not low-level vision,

synchronises audiences during television viewing. Journal of Vision. https://doi.org/10.1167/jov.23.9.4910

Carter, F., Gilchrist, I., & Stanton-Fraser, D. (2025). EEG Functional Connectivity, Heartrate Synchrony, and Eye
Movements Reveal Distinct Components within Narrative Engagement and Immersion.. Journal of cognitive

neuroscience, 1-22. https://doi.org/10.1162/jocn_a_02338

Baldassano, C., Hasson, U., & Norman, K. (2018). Representation of Real-World Event Schemas during Narrative
Perception. The Journal of Neuroscience, 38, 9689 - 9699. https://doi.org/10.1523/JNEUROSCI.0251-18.2018

Suzuki, W., Feliú-Mójer, M., Hasson, U., Yehuda, R., & Zarate, J. (2018). Dialogues: The Science and Power of

Storytelling. The Journal of Neuroscience, 38, 9468 - 9470. https://doi.org/10.1523/JNEUROSCI.1942-18.2018

Chen, Y., Zada, Z., Nastase, S., Ashby, F., & Ghosh, S. (2025). Context modulates brain state dynamics and
behavioral responses during narrative comprehension. bioRxiv. https://doi.org/10.1101/2025.04.05.647323

Chang, C., Nastase, S., & Hasson, U. (2021). Information flow across the cortical timescale hierarchy during
narrative construction. Proceedings of the National Academy of Sciences of the United States of America, 119.
https://doi.org/10.1073/pnas.2209307119

Finn, E., Corlett, P., Chen, G., Bandettini, P., & Constable, R. (2018). Trait paranoia shapes inter-subject synchrony in
brain activity during an ambiguous social narrative. Nature Communications, 9. https://doi.org/10.1038/s41467-
018-04387-2

Li, Z., Li, J., Hong, B., Nolte, G., Engel, A., & Zhang, D. (2021). Speaker-Listener Neural Coupling Reveals an

Adaptive Mechanism for Speech Comprehension in a Noisy Environment.. Cerebral cortex.
https://doi.org/10.1093/cercor/bhab118

Piazza, E., Cohen, A., Trach, J., & Lew‐Williams, C. (2020). Neural synchrony predicts children's learning of novel
words. Cognition, 214. https://doi.org/10.1101/2020.07.28.216663

Li, Z., Hong, B., Wang, D., Nolte, G., Engel, A., & Zhang, D. (2022). Speaker-listener neural coupling reveals a right-
lateralized mechanism for non-native speech-in-noise comprehension.. Cerebral cortex.

https://doi.org/10.1093/cercor/bhac302

9 / 9

