# Extracted Text for REDISH_2002_Teaching_Physics_Suite_critique_of_traditional_assessment_and_support_for_alternative_methods.md.pdf

DOCUMENT SUMMARY

This document, "Teaching Physics with the Physics Suite" by Edward F. Redish, is an extensive
guide for physics instructors that is deeply rooted in cognitive science and physics education 
research (PER). While ostensibly about physics, its core arguments provide a powerful critique 
of traditional, passive, one-size-fits-all models of teaching and assessment. It is highly relevant 
to Enlitens' mission because it systematically dismantles the assumptions behind standardized 
testing by providing evidence for the context-dependent, individualized, and constructive nature 
of learning, advocating for assessment methods (like qualitative questions, essays, and context-
based problems) that probe deep understanding and thinking processes rather than algorithmic 
recall.

FILENAME

REDISH_2002_Teaching_Physics_Suite_critique_of_traditional_assessment_and_support_for_
alternative_methods.md

METADATA

● Primary Category: ASSESSMENT
● Document Type: clinical_guide
● Relevance: Core
● Key Topics: assessment_critique, cognitive_science, learning_theory, 

alternative_assessment, constructivism, context-dependence, individual_differences, 
stereotype_threat

● Tags: #assessment, #critique, #standardized_testing, #alternative_assessment, 

#cognitive_science, #constructivism, #neurodiversity, #stereotype_threat, #context, 
#metacognition

CRITICAL QUOTES FOR ENLITENS

● "To understand what will work, we have to concentrate on what the student is learning 

instead of on what we are teaching."

● "We have to do more than evaluate our students' success. We have to listen and 

analyze what they are thinking and how they learn."

● "What is particularly gratifying is that the improved learning that takes place as a result of
instructional reform based on an understanding of how students think is not limited to the
'middle of the road' student... physics education research has consistently documented 
that the top students in the class show even stronger gains than the midrange students 
from research-motivated cognitive-based curriculum reforms."

● "...students frequently can solve complex algorithmic problems without having a good 

understanding of the physics."

● "It's better to say that we are a community working together to create the best way of 
thinking about the world that we can. This places the knowledge firmly where it really 
resides in the head of the scientist as a part of a scientific community."

● "The most important single factor influencing learning is what the student already knows.

Ascertain this and teach him accordingly." - D. P. Ausubel

● "An 'average' approach will miss everyone because no student is average in all ways."
● "Our own personal experiences may be a very poor guide for telling us the best way to 

teach our students."

● "Never, ever put down a student’s comment in class or embarrass a student in front of 

classmates."

KEY STATISTICS & EVIDENCE

Failure of Traditional Problem-Solving to Build Conceptual Understanding

A study of Korean college physics students who had completed a rigorous high school program 
was investigated.

● "The students Kim studied had taken an apparently much more rigorous high school 

physics program in which each student had done an average of about 1500 problems 
(ranging between 300 and 2900) end-of- chapter problems."

● "In a typical American high school class, students will do 300 to 400 such problems."
● "Despite doing 5 to 10 times as many problems as American students, the students still 
had substantial conceptual difficulties with fundamental concepts of mechanics at rates 
comparable to those seen with American students."

● "There was little correlation between the number of problems the students had done and

the conceptual understanding displayed."

Context-Dependence in Student Performance

At the University of Maryland, engineering physics students were given two equivalent problems
testing Newton's first law, one in a typical physics class context and one in a common-speech, 
everyday context from the Force Concept Inventory (FCI).

● "Although 25 (~90%) got the exam question correct, only 15 of the students (~55%) got 

the FCI question right."

● "Nearly half of the students who succeeded with the problem in the exam context missed

the question presented in a nonphysics context (11/25 ~ 45%)."

Stereotype Threat in Assessment

A study by Claude Steele on gender threat in mathematics testing for college sophomores who 
were math majors or minors.

● One group was told a test was "just a trial." A second group was told the test "showed 

gender differences."

● "In the group given the test without any comment about gender, males and females 

scored approximately the same."

● "In the group with the comment about gender, referred to as a gender threat by Steele, 
females scored significantly worse (by more than a factor of 3!), and males scored 
somewhat better (about 50%)."

● "The implication appears to be that stereotypes (males are better in math) pervade our 
culture in a profound way, with implications that we tend to be unaware of and are 
insensitive to."

Failure of Algorithmic vs. Conceptual Problems

Eric Mazur gave an examination to his algebra-based physics class with two problems: a 
complex quantitative problem and a simpler qualitative/conceptual problem on the same topic 
(DC circuits).

● "The average score on the first problem was 75%; the average score on the second was

40%."

● "Students found problem 2 much more difficult than problem 1, despite the fact that most
physicists would consider the analysis of the second problem, the short circuit, much 
simpler; indeed, parts of it might be considered trivial."

THEORETICAL FRAMEWORKS

A Cognitive Model for Learning

The author outlines a model of human cognition highly relevant to assessment design, based on
five "foothold principles."

1. The constructivism principle

Principle 1: Individuals build their knowledge by making connections to existing knowledge; they
use this knowledge by productively creating a response to the information they receive.

This principle summarizes the core of the fundamental ideas about the structure of long-term 
memory and recall. The basic mechanism of the cognitive response is context-dependent 
association.

2. The context principle

Principle 2: What people construct depends on the context including their mental states.

It’s very easy to forget the warnings and drop back into the model that assumes students either 
know something or don’t. Focusing on the context dependence of a response helps us keep in 
mind that the situation is not that simple.

3. The change principle

Principle 3: It is reasonably easy to learn something that matches or extends an existing 
schema, but changing a well-established schema substantially is difficult.

● Corollary 3.1: It's hard to learn something we don't almost already know.

● Corollary 3.2: Much of our learning is done by analogy.
● Corollary: 3.4: It is very difficult to change an established mental model.

4. The individuality principle

Principle 4: Since each individual constructs his or her own mental structures, different students 
have different mental responses and different approaches to learning. Any population of 
students will show a significant variation in a large number of cognitive variables.

I like to call this principle the individuality or distribution function principle. This reminds us that 
many variables in human behavior have a large natural line width. The large standard deviation 
obtained in many educational experiments is not experimental error; it is part of the measured 
result! As physicists, we should be accustomed to such data. We just aren't used to its being so 
broad and having so many variables. An "average" approach will miss everyone because no 
student is average in all ways.

● Corollary 4.1: People have different styles of learning.
● Corollary 4.2: There is no unique answer to the question: What is the best way to 

teach a particular subject?

● Corollary 4.3: Our own personal experiences may be a very poor guide for telling 

us the best way to teach our students.

● Corollary 4.4: The information about the state of our students' knowledge is contained 
within them. If we want to know what they know, we not only have to ask, we have to 
listen!

5. The social learning principle

Principle 5: For most individuals, learning is most effectively carried out via social interactions.

The "Dead Leaves Model" of Learning

The author critiques the common student mental model for learning science, which is often 
encouraged by traditional assessment. "Unfortunately, the most common mental model for 
learning science in my classes seems to be:

● Write down every equation or law the teacher puts on the board that is also in the book.
● Memorize these, together with the list of formulas at the end of each chapter.
● Do enough homework and end-of-the-chapter problems to recognize which formula is to 

be applied to which problem.

● Pass the exam by selecting the correct formulas for the problems on the exam.
● Erase all information from your brain after the exam to make room for the next set of 

materials."
 "I call the bulleted list above 'the dead leaves model.' It’s as if physics were a collection 
of equations on fallen leaves. One might holds

 s=21gt2, another F
equations is considered to have equivalent weight, importance, and 
structure. The only thing one needs to do when solving a problem is to flip 
through one’s collection of leaves until one finds the appropriate equation."

, and a third F=−kx. Each of these 

=ma

METHODOLOGY DESCRIPTIONS

The Clinical Value of Listening to Student Thinking

The author provides an example of a student who was appalled by a conceptual test, which led 
to a paradigm shift in the instructor's understanding. "Upon looking at the questions, one student
asked: 'Professor Mazur, how should I answer these questions? According to what you taught 
us, or by the way I think about these things?' Mazur was appalled at how many 'trivial' questions
his students missed."

The author also shares a personal example of failing to recognize a common student 
misconception until it was revealed by research data. "But despite my respect for Arons' 
insights, I was skeptical about the importance of a possible student confusion between electric 
charge and magnetic poles. Indeed, I felt my personal experience contradicted it. The point was 
only convincingly brought home to me by the solid experimental data offered by the UWPEG."

Metacognitive Interviewing Technique

Alan Schoenfeld's method for developing metacognition in students is a model for clinical 
interviewing. "Schoenfeld developed an instructional method to help students become more 
metacognitively aware. The key was the mantra of metacognitive questions posted on the wall 
shown in Figure 3.3.

● What (exactly) are you doing? (Can you describe it precisely?)
● Why are you doing it? (How does it fit into the solution?)
● How does it help you? (What will you do with the outcome when you get it?)"

 "At the beginning of the course the students were unable to answer the questions, and 
they were embarrassed by that fact. They began to discuss the questions in order to 
protect themselves against further embarrassment. By the middle of the term, asking the
questions of themselves (not formally, of course) had become habitual behavior for 
some of the students."

Principles of Formative Feedback

"Redish's fourth teaching commandment: Find out as much as you can about what your 
students are thinking."

"Redish's fifth teaching commandment: When students ask you a question or for help, don’t 
answer right away. Ask them questions first, in order to see whether your assumptions about 
their question are correct."

POPULATION-SPECIFIC FINDINGS

Stereotype Threat and Performance

"Stanford sociologist Claude Steele explored the implications of raising the link in a student’s 
mind to gender or race in conjunction with a mathematics test. College sophomores who had 

committed themselves to a math major or minor were given a test somewhat above their level. 
One group was told that the test was 'just a trial' and that the researchers 'wanted to see how 
they would do.' A second group was told up front that the test 'showed gender differences.' (The
sign of the difference was not specified.) The results, shown in Figure 3.5, were dramatic. In the 
group given the test without any comment about gender, males and females scored 
approximately the same. In the group with the comment about gender, referred to as a gender 
threat by Steele, females scored significantly worse (by more than a factor of 3!), and males 
scored somewhat better (about 50%). The implication appears to be that stereotypes (males are
better in math) pervade our culture in a profound way, with implications that we tend to be 
unaware of and are insensitive to. This certainly suggests that we should be extremely cautious 
about making any comments at all about gender or race to our classes. For researchers, it 
suggests that in doing interviews or surveys, questions about the respondent’s gender, race, or 
other social factors should be given separately after the testing is complete."

Learning Differences and the Instructor's Bias

"Physics teachers are an atypical group. We 'opted in' at an early stage in our careers because 
we liked physics for one reason or another. We then trained for up to a dozen years before we 
started teaching our own classes. This training stretches us even farther from the style of 
approach of the 'typical' student. Is it any wonder that we don’t understand most of our 
beginning students and they don’t understand us? I vividly recall a day a few years ago when a 
student in my algebra-based introductory physics class came in to ask about some motion 
problems. I said: 'All right, let’s get down to absolute basics. Let’s draw a graph.' The student’s 
face fell, and I realized suddenly that a graph was not going to help him at all."

PRACTICAL APPLICATIONS 
(ALTERNATIVE ASSESSMENTS)

Critiques of Traditional Testing

● "Traditional testing often fails to show us what students really think or know because 

many different schemas can produce the correct solution to a problem."

● "Even if a student goes through the same steps as we do, there’s no guarantee that their
schema for choosing the steps is the same as ours. I once asked a student, who had 
done a homework problem correctly, to explain his solution. He replied: 'Well, we’ve 
used all of the other formulas at the end of the chapter except this one, and the unknown
starts with the same letter as is in that formula, so that must be the one to use.'"
● "If we construct our exams from homework problems they have been assigned, our 
students are likely to seek out correct solutions from friends or solution books and to 
memorize them without making the effort to understand or make sense of them."
● "If all our exam problems can be solved by coming up with the 'right equation' and 
turning the crank, students will memorize lists of equations and pattern match."

Eight Types of Alternative Exam and Homework Questions

The author proposes a variety of question types that go beyond simple "plug-and-chug" 
problems to assess deeper understanding.

1. Multiple-choice and short-answer questions (with research-based distractors): 
"The use of common misconceptions or facets as distractors produces 'attractive 
nuisances' that challenge the students' understanding. Students who get the correct 
answer despite these challenges are likely to have a reasonably good understanding."

2. Multiple-choice multiple-response questions: "A substantial amount of thinking and 
reasoning can be required from a student... This type of question requires a student to 
evaluate each statement and make a decision about it. It is a particularly useful type of 
question in cases where students tend to have mixed context-dependent models of a 
physical situation."

3. Representation-translation questions: "Learning to handle the variety of 

representations we use can be quite a challenge for introductory students, but it can be 
one of the most valuable general skills they develop from studying physics. The 
presentation of a single situation in different ways facilitates understanding and sense-
making of different facets of the situation."

4. Ranking tasks: "Ranking tasks are effective because they easily trigger reasoning 
primitives such as 'more of a cause produces (proportionately) more of an effect'."

5. Context-based reasoning problems: "In these problems, students are given a 
reasonably realistic situation and have to use physics principles often in ways or 
circumstances in that they have not been previously seen to come to a conclusion... The
crucial fact is that the answer to the problem should be of some reasonable real-world 
interest."

6. Estimation problems: "Questions of this type can have considerable value because 

⚫
students 
numbers 
⚫
experience."

 get to practice and apply proportional reasoning 
 learn to think about significant figures... 

 learn to work with large 
 learn to quantify their real-world 

⚫

⚫

7. Qualitative questions: "Qualitative questions can be quite effective in getting students 
to learn to think about concepts and in helping instructors realize that students may not 
have learned what they thought they had from observing good performance on 
quantitative problem solving... Note that an essential part of questions of this type is the 
phrase 'explain your reasoning.'"

8. Essay questions: "Essay questions can be the most revealing of students' difficulties 

and naïve conceptions of any form."

