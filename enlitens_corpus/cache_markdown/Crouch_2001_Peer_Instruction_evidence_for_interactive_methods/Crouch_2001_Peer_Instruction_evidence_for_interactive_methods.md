# Extracted Text for Crouch_2001_Peer_Instruction_evidence_for_interactive_methods.pdf

DOCUMENT SUMMARY

This paper details ten years of results from implementing Peer Instruction (PI), a pedagogy that 
replaces passive lecturing with active, collaborative conceptual questioning. The research 
provides compelling evidence that interactive methods are superior to traditional instruction, not 
only for improving conceptual understanding but also for enhancing quantitative problem-solving
skills. This is core evidence for Enlitens, demonstrating that moving away from rigid, traditional 
methods leads to deeper and more robust learning, and provides a framework for explaining 
and overcoming resistance to new, more effective approaches.

FILENAME

Crouch_2001_Peer_Instruction_evidence_for_interactive_methods

METADATA

● Primary Category: RESEARCH
● Document Type: research_article
● Relevance: Core
● Key Topics: pedagogy, alternative_assessment, evidence-based_practice, 

standardized_testing_critique, student_motivation, conceptual_understanding, 
collaborative_learning

● Tags: #pedagogy, #assessment_critique, #standardized_testing, #collaboration, 

#active_learning, #motivation, #resistance, #implementation, #evidence, 
#conceptual_change

CRITICAL QUOTES FOR ENLITENS

● "In recent years, physicists and physics educators have re-alized that many students 

learn very little physics from tra-ditional lectures."

● "traditionally taught courses do little to improve students understanding of the central 

concepts of physics, even if the students successfully learn problem-solving algorithms."
● "students develop complex reasoning skills most effectively when actively engaged with 

the material they are studying, and have found that cooperative activities are an 
excellent way to engage students effectively."

● "Unlike the common practice of asking infor-mal questions during a lecture, which 

typically engages only a few highly motivated students, the more structured ques-tioning 
process of PI involves every student in the class."

● "All measures indicate that our students' quanti-tative problem-solving skills are 

comparable to or better than those achieved with traditional instruction, consistent with 
the findings of Thacker et al."

● "the vast majority of students who revise their answers during discussion change from 

an incorrect answer to the correct answer."

● "we find that no stu-dent gave the correct answer to the ConcepTests prior to discussion 
more than 80% of the time, indicating that even the strongest students are challenged by
the ConcepTests and learn from them."

● "In traditional introductory science courses, students gener-ally read the textbook only 

after the lecturer has covered the topic (if ever)."

● "in the classroom, the instructor must not be discouraged by complaints such as, 'When 
are we going to do some real physics?' and must continue to explain to students the rea-
sons that the course is taught this way."

● "It is common for some or many students to be initially skeptical about this form of 

instruction. Consequently, proper motivation of the stu-dents is essential."

● "It is important to note that student evaluations and attitude are not a measure of student
learning; as discussed in Sec. II, we saw high learning gains for the students in the 
algebra-based course in spite of lower perceived satisfaction overall."

● "research indicates that student evaluations are based heavily on instructor personality³¹ 

rather than course effectiveness."

● "Another challenge is students' resistance to the method (7% of respondents). Because 
most students are unaccustomed to active participa-tion in science classes, some feel 
uncomfortable participating in discussions, or initially consider the discussions a waste of
time."

KEY STATISTICS & EVIDENCE

● Conceptual Mastery (FCI Test):

○ Upon changing from traditional instruction to Peer Instruction (PI), the average 

normalized gain on the Force Concept Inventory (FCI) doubled from 0.25 to 0.49.

○ With continued refinements to the PI method, the normalized gain steadily 

increased, reaching 0.74 in 1997.

○ A traditionally taught algebra-based course in 1999 produced a normalized gain 
of 0.40, while the same course taught with PI in 1998 and 2000 produced gains 
of 0.65 and 0.63, respectively.

● Quantitative Problem Solving:

○ The average score on the Mechanics Baseline Test (MBT) increased from 66% 
with traditional instruction to 72% in the first year of PI, eventually reaching 79%.

○ Performance on a final exam consisting entirely of quantitative problems 

increased from a mean score of 63% (traditional) to 69% (PI), a statistically 
significant increase (p=0.001).

○ On an identical quantitative problem given on a final exam, students taught with 
PI averaged 7.4 out of 10, while students taught traditionally the previous year 
averaged 5.5 out of 10 (effect size of 0.57).

● Effectiveness of Peer Discussion:

○ Analysis of an entire semester of ConcepTests showed that after discussion, the 
number of students giving the correct answer increases substantially, especially 
when the initial correct percentage is between 35% and 70%.

○ For all ConcepTests in Fall 1997: 40% of answer pairs were correct both times, 
32% changed from incorrect to correct, 22% were incorrect both times, and only 
6% changed from correct to incorrect.

● Widespread PI Adoption & Success:

○ A survey of 384 PI users found that 90% of courses (27 of 30) fall in the 
"medium-g" range for FCI gains, a range that contains 85% of interactive 
engagement courses and no traditionally taught courses.

○ Of 384 identified PI users, 332 (86%) planned to use PI again, while only 7 had 

no plans to use it again.

Table 1: Force Concept Inventory (FCI) and Mechanics Baseline Test (MBT) 
results

Year

Method

FCI 
pre

FCI 
post

Absolute gain
(post-pre)

Normalized. 
gain (g)

MBT MBT quant. 

N

questions

Calculus-
based

1990

1991

1993

1994

1995

1996

1997

Algebra-
based

1998

1999

2000

Traditional

(70%)

78% 8%

PI

PI

PI

PI

PI

PI

PI

71%

85% 14%

70%

86% 16%

70%

88% 18%

67%

88% 21%

67%

89% 22%

67%

92% 25%

50%

83% 33%

Traditional

(48%)

69% 21%

PI

47%

80% 33%

0.25

0.49

0.55

0.59

0.64

0.68

0.74

0.65

0.40

0.63

66% 62%

72% 66%

71% 68%

76% 73%

76% 71%

74% 66%

79% 73%

68% 59%

66% 69%

121

177

158

216

181

153

117

246

129

126

Export to Sheets

METHODOLOGY DESCRIPTIONS

Peer Instruction (PI) Method Overview

Peer Instruction engages students during class through activities that require each student to 
apply the core concepts being presented, and then to explain those concepts to their fellow 
students. A class is divided into a series of short presentations, each focused on a central point 
and followed by a related conceptual question, called a ConcepTest.

The process for each ConcepTest is as follows:

1.

Individual Thought: Students are given one to two minutes to formulate individual 
answers and report them to the instructor.

2. Peer Discussion: Students then discuss their answers with others sitting nearby. The 
instructor urges students to try to convince each other by explaining their underlying 
reasoning. This discussion typically lasts two to four minutes, during which the instructor 
moves around the room listening.

3. Group Answer & Explanation: The instructor ends the discussion, polls students for 
their answers again (which may have changed), and then explains the correct answer 
before moving to the next topic.

To free up class time for these activities, students are required to complete reading on the 
topics before class.

Pre-Class Reading Assignments

To incentivize and guide pre-class reading, the instructors replaced reading quizzes with an 
adaptation of "Just-in-Time Teaching". Before each class, a three-question, free-response web 
assignment is due.

● Two questions probe difficult aspects of the reading.
● The third question asks, "What did you find difficult or confusing about the reading? ... 

Please be as specific as possible."

● Students receive credit based on effort, not correctness, which allows for more 

challenging questions and reduces grading effort.

● This feedback allows the instructor to tailor the class to the students' identified needs.

Cooperative Activities in Discussion Sections

To reinforce the interactive pedagogy, discussion sections are structured around cooperative 
activities. In the mechanics semester, a weekly two-hour workshop is held.

● One half is devoted to conceptual reasoning and hands-on activities using the

 Tutorials in Introductory Physics.

● The other half is devoted to quantitative problem solving, where students work in groups 
on homework problems after the instructor models a solution. The instructor circulates 
and helps groups by asking guiding questions rather than giving answers.

POPULATION-SPECIFIC FINDINGS

● The study found different levels of student satisfaction and resistance between two 
distinct populations: a calculus-based course for mostly honors biology or chemistry 
majors, and an algebra-based course for primarily non-science majors.

● In the calculus-based course, student evaluation scores remained high (4.5/5.0) after 
implementing PI, and written comments indicated most students appreciated the 
interactive approach.

● In the algebra-based course, average evaluation scores dropped significantly to 3.4/5.0, 
with more dissatisfied students. The authors surmise that students in this course are "on 
average less interested in the course and more intimidated by the material".

● This difference in satisfaction existed despite the fact that students in the algebra-based 

course achieved high learning gains.

PRACTICAL APPLICATIONS

Strategies for Motivating Students & Overcoming Resistance

● Explain the "Why": It is essential to thoroughly explain the reasons for using a non-
traditional method from the start. The instructor must not be discouraged by initial 
complaints and must continue to explain the rationale.

● Grade What Matters: Including conceptual questions on exams makes it clear that 

conceptual understanding is taken seriously. Providing equation sheets or using open-
book exams shifts the focus away from memorization.

● Show Them the Data: Regularly presenting class-averaged data on performance can 
show students that the method is helping them learn and can increase motivation.

● Be Persistent: Instructors report that while students may be initially skeptical, they often
"warmed up to it as they found the method helped them learn the material". A period of 
adjustment is normal when learning a new way of doing things.

● Circulate and Engage: To fully engage students in discussions, it is important for the 
instructor to circulate through the classroom, helping to guide and encourage students.

Overcoming Implementation Challenges

● Time to Develop Materials: 13% of instructors cite the time needed to create good 

ConcepTests as an impediment.
 Solution: Use publicly available, free databases of questions developed by others to 
minimize duplication of effort.

● Colleague Skepticism: 10% of respondents report skeptical colleagues who question 

taking away lecture time.
 Solutions: Collect and share data on student learning gains, compare exam results 
with and without PI, invite skeptics to class, or share positive student feedback.
● Syllabus Coverage: 9% of respondents find it difficult to devote class time to 

ConcepTests due to the quantity of material to cover.
 Solutions: Some instructors reduce the amount of material covered. The majority 
require students to learn some material on their own, especially by assigning and 
incentivizing pre-class reading.

● Student Resistance: 7% of respondents cite student resistance to active participation.

 Solutions: Thoroughly explain the pedagogy, be persistent, show students 
performance data, and have the instructor circulate during discussions to encourage 
participation.

