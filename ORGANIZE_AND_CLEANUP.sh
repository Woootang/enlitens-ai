#!/bin/bash
# Organize & Clean - Creates a proper hierarchy and removes unused files
# This will make your project CLEAN and ORGANIZED

set -e

echo "ðŸ§¹ ENLITENS-AI ORGANIZE & CLEANUP"
echo "===================================="
echo ""
echo "This will:"
echo "  1. Organize loose files into proper folders"
echo "  2. Remove unused/duplicate files"
echo "  3. Create a clean hierarchy"
echo ""
echo "âœ… KEEPS:"
echo "  - src/ (PDF processing)"
echo "  - enlitens_client_profiles/ (personas)"
echo "  - enlitens_corpus/ (PDFs)"
echo "  - enlitens_knowledge_base/ (data)"
echo "  - All .pdf, .zip files"
echo ""
echo "âŒ REMOVES:"
echo "  - Monitoring files"
echo "  - Test files"
echo "  - Old docs"
echo "  - Duplicate files"
echo "  - Log files"
echo ""
read -p "Continue? (y/N) " -n 1 -r
echo
if [[ ! $REPLY =~ ^[Yy]$ ]]; then
    echo "Cancelled."
    exit 1
fi

cd /home/antons-gs/enlitens-ai

echo ""
echo "ðŸ“ Creating organized folder structure..."

# Create organized structure
mkdir -p _archive/old_docs
mkdir -p _archive/old_logs
mkdir -p _archive/old_scripts
mkdir -p docs/reports
mkdir -p scripts

echo "âœ… Created: _archive/, docs/, scripts/"

echo ""
echo "ðŸ“¦ Moving documentation files..."
mv -f DEEP_RESEARCH_PROMPT.md docs/ 2>/dev/null || true
mv -f PERSONA_GENERATION_FINAL_REPORT.md docs/reports/ 2>/dev/null || true
mv -f PERSONA_INTEGRATION_PLAN.md docs/ 2>/dev/null || true
mv -f CLEANUP_AND_FIX_PLAN.md docs/ 2>/dev/null || true
mv -f README_KNOWLEDGE_BASE.md docs/ 2>/dev/null || true
mv -f README_MULTI_AGENT_SYSTEM.md docs/ 2>/dev/null || true
echo "âœ… Organized: Documentation â†’ docs/"

echo ""
echo "ðŸ“¦ Archiving old documentation..."
mv -f FIXES_SUMMARY.md _archive/old_docs/ 2>/dev/null || true
mv -f IMMEDIATE_FIXES.md _archive/old_docs/ 2>/dev/null || true
mv -f QUICKSTART_MONITORING.md _archive/old_docs/ 2>/dev/null || true
mv -f MONITORING_README.md _archive/old_docs/ 2>/dev/null || true
echo "âœ… Archived: Old docs â†’ _archive/old_docs/"

echo ""
echo "ðŸ“¦ Moving scripts..."
mv -f start_processing.sh scripts/ 2>/dev/null || true
mv -f add_new_pdfs.py scripts/ 2>/dev/null || true
echo "âœ… Organized: Scripts â†’ scripts/"

echo ""
echo "ðŸ“¦ Archiving old scripts..."
mv -f fix_ollama_gpu.sh _archive/old_scripts/ 2>/dev/null || true
mv -f stable_run.sh _archive/old_scripts/ 2>/dev/null || true
mv -f start_monitoring.sh _archive/old_scripts/ 2>/dev/null || true
echo "âœ… Archived: Old scripts â†’ _archive/old_scripts/"

echo ""
echo "ðŸ“¦ Archiving log files..."
mv -f *.log _archive/old_logs/ 2>/dev/null || true
echo "âœ… Archived: Logs â†’ _archive/old_logs/"

echo ""
echo "ðŸ—‘ï¸  Removing monitoring files..."
rm -f monitoring_server*.py test_monitoring_server.py monitor_processing.py check_progress.py 2>/dev/null || true
rm -f test_dashboard.html style.css requirements-monitoring.txt 2>/dev/null || true
rm -f cloudflared 2>/dev/null || true
echo "âœ… Removed: Monitoring files"

echo ""
echo "ðŸ—‘ï¸  Removing duplicate data files..."
rm -f intakes.txt transcripts.txt 2>/dev/null || true
echo "âœ… Removed: Duplicate intakes.txt, transcripts.txt (kept in enlitens_knowledge_base/)"

echo ""
echo "ðŸ—‘ï¸  Removing unused directories..."
rm -rf docs/old_structure 2>/dev/null || true
rm -rf golden_dataset/ monitoring_ui/ pyairports/ test_input/ tests/ 2>/dev/null || true
rm -rf .vscode/ .worktrees/ 2>/dev/null || true
echo "âœ… Removed: Unused directories"

echo ""
echo "ðŸ—‘ï¸  Cleaning Python cache..."
find . -type d -name "__pycache__" -exec rm -rf {} + 2>/dev/null || true
find . -type f -name "*.pyc" -delete 2>/dev/null || true
echo "âœ… Cleaned: Python cache"

echo ""
echo "ðŸ—‘ï¸  Removing unused src/ subdirectories..."
cd src/
rm -rf cli/ monitoring/ pipeline/ schema/ testing/ 2>/dev/null || true
echo "âœ… Removed: cli, monitoring, pipeline, schema, testing from src/"

echo ""
echo "ðŸ—‘ï¸  Cleaning unused files in src/agents/..."
cd agents/
rm -f clinical_synthesis_agent.py context_rag_agent.py educational_content_agent.py 2>/dev/null || true
rm -f enhanced_complete_enlitens_agent.py base_agent.py 2>/dev/null || true
echo "âœ… Kept only: extraction_team.py, supervisor_agent.py"

echo ""
echo "ðŸ—‘ï¸  Cleaning unused files in src/extraction/..."
cd ../extraction/
rm -f enhanced_pdf_extractor_v2.py pdf_extractor.py 2>/dev/null || true
echo "âœ… Kept only: enhanced_pdf_extractor.py, enhanced_extraction_tools.py"

echo ""
echo "ðŸ—‘ï¸  Cleaning unused files in src/retrieval/..."
cd ../retrieval/
rm -f chunker.py hybrid_retriever.py index_maintenance.py 2>/dev/null || true
echo "âœ… Kept only: embedding_ingestion.py"

echo ""
echo "ðŸ—‘ï¸  Cleaning unused files in src/synthesis/..."
cd ../synthesis/
rm -f ai_synthesizer.py enlitens_rebellion_synthesizer.py few_shot_library.py prompts.py 2>/dev/null || true
echo "âœ… Kept only: ollama_client.py"

echo ""
echo "ðŸ—‘ï¸  Cleaning unused files in src/utils/..."
cd ../utils/
rm -f prompt_cache.py retry.py settings.py 2>/dev/null || true
echo "âœ… Kept only: enhanced_logging.py, terminology.py"

echo ""
echo "ðŸ—‘ï¸  Removing src/validation/ (unused)..."
cd ..
rm -rf validation/ 2>/dev/null || true
echo "âœ… Removed: validation/"

cd /home/antons-gs/enlitens-ai

echo ""
echo "ðŸ“ Creating README.md..."
cat > README.md << 'READMEEOF'
# Enlitens AI - Client Profile & Knowledge Base System

## ðŸ“ Project Structure

```
enlitens-ai/
â”œâ”€â”€ src/                              # Core PDF processing code
â”‚   â”œâ”€â”€ agents/                       # Multi-agent system
â”‚   â”‚   â”œâ”€â”€ extraction_team.py        # Extraction agent team
â”‚   â”‚   â””â”€â”€ supervisor_agent.py       # Supervisor agent
â”‚   â”œâ”€â”€ extraction/                   # PDF extraction
â”‚   â”‚   â”œâ”€â”€ enhanced_pdf_extractor.py
â”‚   â”‚   â””â”€â”€ enhanced_extraction_tools.py
â”‚   â”œâ”€â”€ models/                       # Data schemas
â”‚   â”‚   â””â”€â”€ enlitens_schemas.py
â”‚   â”œâ”€â”€ retrieval/                    # Embeddings & retrieval
â”‚   â”‚   â””â”€â”€ embedding_ingestion.py
â”‚   â”œâ”€â”€ synthesis/                    # LLM synthesis
â”‚   â”‚   â””â”€â”€ ollama_client.py
â”‚   â”œâ”€â”€ utils/                        # Utilities
â”‚   â”‚   â”œâ”€â”€ enhanced_logging.py
â”‚   â”‚   â””â”€â”€ terminology.py
â”‚   â””â”€â”€ knowledge_base/               # Knowledge management
â”‚       â””â”€â”€ knowledge_manager.py
â”‚
â”œâ”€â”€ enlitens_client_profiles/         # Client persona system
â”‚   â”œâ”€â”€ profiles/                     # 57 generated personas
â”‚   â”œâ”€â”€ clusters/                     # Intake clusters
â”‚   â””â”€â”€ *.py                          # Persona generation scripts
â”‚
â”œâ”€â”€ enlitens_corpus/                  # Research PDFs
â”‚   â””â”€â”€ input_pdfs/                   # PDFs to process
â”‚
â”œâ”€â”€ enlitens_knowledge_base/          # Client data
â”‚   â”œâ”€â”€ intakes.txt                   # 224 client intakes
â”‚   â””â”€â”€ transcripts.txt               # Session transcripts
â”‚
â”œâ”€â”€ scripts/                          # Main scripts
â”‚   â”œâ”€â”€ start_processing.sh           # Start PDF processing
â”‚   â””â”€â”€ add_new_pdfs.py               # Add new PDFs incrementally
â”‚
â”œâ”€â”€ docs/                             # Documentation
â”‚   â””â”€â”€ reports/                      # Analysis reports
â”‚
â”œâ”€â”€ process_multi_agent_corpus.py     # Main PDF processing script
â”œâ”€â”€ requirements.txt                  # Python dependencies
â”œâ”€â”€ venv/                             # Python virtual environment
â”œâ”€â”€ logs/                             # Processing logs
â”œâ”€â”€ cache/                            # Caching
â””â”€â”€ _archive/                         # Archived old files

```

## ðŸš€ Quick Start

### Process PDFs to Create Knowledge Base
```bash
cd /home/antons-gs/enlitens-ai
./scripts/start_processing.sh
```

### View Generated Personas
```bash
python -m enlitens_client_profiles.view_persona
```

### Generate New Personas (when you have new intakes)
```bash
python -m enlitens_client_profiles.cluster_intakes 50
python -m enlitens_client_profiles.generate_from_clusters --full
```

## ðŸ“Š Current Status

- âœ… **57 Client Personas** generated from 224 real intakes
- âœ… **50 Client Segments** identified via clustering
- â³ **Knowledge Base** - Ready to process PDFs
- â³ **Confidence Scoring** - To be implemented
- â³ **External Search** - To be implemented

## ðŸŽ¯ Next Steps

1. Process PDFs with persona integration
2. Add confidence scoring system
3. Add external search for knowledge gaps
4. Generate training pairs for fine-tuning

## ðŸ“– Documentation

- [Persona Generation Report](docs/reports/PERSONA_GENERATION_FINAL_REPORT.md)
- [Multi-Agent System](docs/README_MULTI_AGENT_SYSTEM.md)
- [Knowledge Base](docs/README_KNOWLEDGE_BASE.md)

READMEEOF

echo "âœ… Created: README.md"

echo ""
echo "âœ… ORGANIZATION & CLEANUP COMPLETE!"
echo ""
echo "ðŸ“Š NEW CLEAN STRUCTURE:"
echo ""
echo "enlitens-ai/"
echo "â”œâ”€â”€ ðŸ“ src/                        # Core code"
echo "â”œâ”€â”€ ðŸ“ enlitens_client_profiles/   # 57 personas"
echo "â”œâ”€â”€ ðŸ“ enlitens_corpus/            # Your PDFs"
echo "â”œâ”€â”€ ðŸ“ enlitens_knowledge_base/    # Data (intakes, transcripts)"
echo "â”œâ”€â”€ ðŸ“ scripts/                    # Main scripts"
echo "â”œâ”€â”€ ðŸ“ docs/                       # Documentation"
echo "â”œâ”€â”€ ðŸ“ _archive/                   # Old files (safe to delete later)"
echo "â”œâ”€â”€ ðŸ“„ process_multi_agent_corpus.py"
echo "â”œâ”€â”€ ðŸ“„ requirements.txt"
echo "â”œâ”€â”€ ðŸ“„ README.md"
echo "â””â”€â”€ ðŸ“ venv/"
echo ""
echo "ðŸŽ¯ Next steps:"
echo "   1. Test PDF processing:"
echo "      cd /home/antons-gs/enlitens-ai"
echo "      ./scripts/start_processing.sh"
echo ""
echo "   2. View your personas:"
echo "      python -m enlitens_client_profiles.view_persona"
echo ""
echo "   3. Delete _archive/ folder when ready (contains old files)"

